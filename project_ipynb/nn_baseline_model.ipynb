{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/5j/xbk2d6w57vg_6xk0cdm9x72w0000gn/T/ipykernel_19714/4133603028.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihaoq/opt/anaconda3/envs/ggbaker/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84800</td>\n",
       "      <td>0.400</td>\n",
       "      <td>165360</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>-11.794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>79.545</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.56000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>127027</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-6.163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>109.039</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.57100</td>\n",
       "      <td>0.467</td>\n",
       "      <td>148533</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>-13.049</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>86.895</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78900</td>\n",
       "      <td>0.522</td>\n",
       "      <td>134520</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>-3.480</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>141.010</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.60800</td>\n",
       "      <td>0.635</td>\n",
       "      <td>145013</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>-5.125</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>139.426</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>0.02640</td>\n",
       "      <td>0.611</td>\n",
       "      <td>132303</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>-5.688</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>178.462</td>\n",
       "      <td>0.393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>0.69200</td>\n",
       "      <td>0.824</td>\n",
       "      <td>209438</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>-6.400</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>98.027</td>\n",
       "      <td>0.513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>0.32100</td>\n",
       "      <td>0.834</td>\n",
       "      <td>247059</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>-9.750</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>81.618</td>\n",
       "      <td>0.837</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514</th>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.896</td>\n",
       "      <td>196653</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>-6.687</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>116.971</td>\n",
       "      <td>0.642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9515</th>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.514</td>\n",
       "      <td>200040</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>171.005</td>\n",
       "      <td>0.334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9516 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0          0.84800         0.400       165360   0.205          0.000000    7   \n",
       "1          0.56000         0.686       127027   0.844          0.000001   10   \n",
       "2          0.57100         0.467       148533   0.277          0.001160    9   \n",
       "3          0.78900         0.522       134520   0.673          0.000000   11   \n",
       "4          0.60800         0.635       145013   0.829          0.000000    9   \n",
       "...            ...           ...          ...     ...               ...  ...   \n",
       "9511       0.02640         0.611       132303   0.688          0.000000    1   \n",
       "9512       0.69200         0.824       209438   0.588          0.000104    6   \n",
       "9513       0.32100         0.834       247059   0.454          0.000006    1   \n",
       "9514       0.10400         0.896       196653   0.586          0.000000   10   \n",
       "9515       0.00146         0.514       200040   0.730          0.000095    1   \n",
       "\n",
       "      liveness  loudness  popularity  speechiness    tempo  valence  \\\n",
       "0       0.4000   -11.794         1.0       0.0270   79.545    0.357   \n",
       "1       0.1200    -6.163         2.0       0.0484  109.039    0.897   \n",
       "2       0.0762   -13.049         5.0       0.0302   86.895    0.597   \n",
       "3       0.3180    -3.480         5.0       0.0425  141.010    0.659   \n",
       "4       0.1860    -5.125         6.0       0.0471  139.426    0.963   \n",
       "...        ...       ...         ...          ...      ...      ...   \n",
       "9511    0.2510    -5.688        94.0       0.3410  178.462    0.393   \n",
       "9512    0.1490    -6.400        94.0       0.0924   98.027    0.513   \n",
       "9513    0.1140    -9.750        95.0       0.2010   81.618    0.837   \n",
       "9514    0.7900    -6.687        95.0       0.0559  116.971    0.642   \n",
       "9515    0.0897    -5.934       100.0       0.0598  171.005    0.334   \n",
       "\n",
       "      popularity_level  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "9511                 2  \n",
       "9512                 2  \n",
       "9513                 2  \n",
       "9514                 2  \n",
       "9515                 2  \n",
       "\n",
       "[9516 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Check if MPS is available and set the device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "df = pd.read_csv('result.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7612, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5000/5000 [00:35<00:00, 141.53it/s, Training Loss=0.8250, Test Loss=1.0801, Training Accuracy=0.6272, Test Accuracy=0.4737]\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "features = [\"loudness\", \"energy\", \"speechiness\", \"danceability\", \"tempo\", \"key\", \"liveness\", \"instrumentalness\", \"valence\", \"acousticness\", \"duration_ms\"]\n",
    "target = \"popularity_level\"\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('minmax', MinMaxScaler(), [\n",
    "        'tempo', 'duration_ms', 'loudness', \n",
    "        'energy', 'speechiness', 'danceability', 'liveness', \n",
    "        'instrumentalness', 'valence',  \n",
    "        'acousticness'\n",
    "    ]),\n",
    "    ('categorical', OneHotEncoder(), ['key'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Creating a pipeline with make_pipeline\n",
    "pipeline = make_pipeline(preprocessor)\n",
    "\n",
    "# Fit and transform the data using the pipeline\n",
    "X_train_transformed = pipeline.fit_transform(X_train, y_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "# Print shape to determine input size\n",
    "print(X_train_transformed.shape)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.01)\n",
    "        \n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model with the correct input size\n",
    "input_size = X_train_transformed.shape[1]\n",
    "model = Net(input_size).to(device)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.tensor(X_train_transformed, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_transformed, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.03)\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    _, predicted_classes = torch.max(predictions, 1)\n",
    "    correct = (predicted_classes == labels).float()\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy\n",
    "\n",
    "# Training loop with evaluation\n",
    "epochs = 5000\n",
    "from tqdm import tqdm\n",
    "progress_bar = tqdm(range(epochs), desc='Training')\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            test_loss = criterion(test_outputs, y_test_tensor)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            train_accuracy = calculate_accuracy(outputs, y_train_tensor)\n",
    "            test_accuracy = calculate_accuracy(test_outputs, y_test_tensor)\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Training Loss': f'{loss.item():.4f}',\n",
    "                'Test Loss': f'{test_loss.item():.4f}',\n",
    "                'Training Accuracy': f'{train_accuracy:.4f}',\n",
    "                'Test Accuracy': f'{test_accuracy:.4f}'\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessing_pipeline_baseline.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the entire model\n",
    "torch.save(model, 'model_baseline.pth')\n",
    "\n",
    "# Save the preprocessing pipeline\n",
    "joblib.dump(pipeline, 'preprocessing_pipeline_baseline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggbaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
